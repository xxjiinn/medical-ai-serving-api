# 기술적 의사결정 및 트레이드오프

작성일: 2026-02-17

---

## 1. 프로젝트 주제 선정

### 결정: 의료 AI Inference Serving 백엔드

**선택 이유**:

- 의료 데이터 기반 개발: "의료 AI 모델 Serving 시스템 구축" 명시
- AI 모델 개발보다 **백엔드 서빙 아키텍처** 역량이 핵심
- NHIS 공공데이터: 즉시 접근 가능, 라이선스 제약 없음

**대안 (고려했으나 포기)**:

- 실제 AI 모델 개발 → 파이썬 비숙련 + 짧은 기간에 무리
- PACS 연동 시뮬레이션 → 의료 영상 데이터 확보 어려움

**트레이드오프**:

- ✅ 얻은 것: 백엔드 아키텍처 설계 역량 증명
- ❌ 포기한 것: 실제 딥러닝 모델 구현 경험

---

## 2. 프레임워크 선택

### 결정: Flask (Django 대신)

**선택 이유**:

1. **학습 곡선**: Django보다 가볍고 빠르게 습득 가능 (1주일 제약)
2. **유연성**: Blueprint로 레이어 분리 설계 가능

**대안**:

- Django: ORM/Admin 등 기능 풍부하나 초기 학습 부담
- FastAPI: 비동기 성능 좋으나 SQLAlchemy 경험 우선

**트레이드오프**:

- ✅ 얻은 것: 빠른 개발, 명확한 레이어 분리
- ❌ 포기한 것: Django Admin, 자동 문서화

---

## 3. 데이터베이스 설계

### 결정: MySQL (PostgreSQL 대신)

**선택 이유**:

1. **Railway 지원**: MySQL 바로 사용 가능
2. **충분한 기능**: RDBMS 설계 역량 증명에 충분

**대안**:

- PostgreSQL: JSON 타입 등 고급 기능 많으나 요구사항 초과
- NoSQL: 의료 데이터는 구조화된 RDB가 적합

**트레이드오프**:

- ✅ 얻은 것: 요구사항 정확히 충족, 빠른 설정
- ❌ 포기한 것: JSON 필드 등 고급 기능

---

## 4. 캐시 전략

### 결정: Redis (통계 API만 캐싱)

**선택 이유**:

1. **성능 개선 수치화**: 캐시 전후 비교로 최적화 역량 증명
2. **실무 적합성**: 의료 AI 플랫폼에서 통계 조회는 빈번함
3. **Railway 지원**: Redis 바로 사용 가능

**범위 결정**:

- ✅ 캐싱: `/stats/risk`, `/stats/age` (변경 빈도 낮음)
- ❌ 캐싱 안 함: `/records`, `/simulate` (실시간 데이터)

**대안**:

- Memcached: Redis와 유사하나 데이터 구조 제한적
- 캐시 없음: 성능 최적화 역량 증명 기회 상실

**트레이드오프**:

- ✅ 얻은 것: 성능 개선 수치화, Redis 경험
- ❌ 포기한 것: 캐시 무효화 복잡도 증가

---

## 5. ETL 설계

### 결정: ETL과 Serving 레이어 분리

**선택 이유**:

1. **운영 안정성**: 배치(ETL)와 실시간(API)을 분리
2. **확장성**: ETL 실패해도 API 서비스 중단 없음
3. **실무 적합성**: 의료 AI 플랫폼의 일반적 구조

**구현 방식**:

- ETL: 로컬 스크립트로 실행 → Railway MySQL에 적재
- Serving: Flask API로 DB 조회만

**대안**:

- 통합 구조: CSV 업로드 API로 ETL 수행 → 메모리 부담, 타임아웃 위험

**트레이드오프**:

- ✅ 얻은 것: 안정성, 명확한 책임 분리
- ❌ 포기한 것: 실시간 데이터 업로드 편의성

---

## 6. Inference Layer 분리

### 결정: Service 내부에 Inference Layer 독립

**선택 이유**:

1. **확장성**: 현재 rule 기반 → 향후 ML 모델로 교체 가능
2. **테스트 용이성**: 판정 로직만 독립 테스트 가능
3. **포트폴리오 차별화**: 단순 CRUD가 아닌 아키텍처 설계 증명

**구조**:

```
POST /simulate
 → API Layer (검증)
 → Service Layer (흐름 제어)
 → Inference Layer (위험요인 판정) ← 여기만 교체하면 모델 적용 가능
 → Repository Layer (결과 저장)
```

**트레이드오ff**:

- ✅ 얻은 것: 확장 가능 구조, 설계 역량 증명
- ❌ 포기한 것: 단순한 구조 (초기 개발 속도 느림)

---

## 7. 인증 방식

### 결정: API Key (로그인/회원가입 없음)

**선택 이유**:

1. **범위 집중**: ETL, DB, 캐싱에 집중 (1주일 제약)
2. **충분한 증명**: RESTful API, 미들웨어 설계 역량은 증명 가능
3. **보안**: 개인정보 없어 간단한 인증으로 충분

**구현**:

- `X-API-KEY` 헤더로 검증
- 미들웨어에서 중앙 처리

**대안**:

- JWT: 토큰 발급/갱신 구조 복잡
- OAuth: 외부 인증 연동 시간 소요

**트레이드오프**:

- ✅ 얻은 것: 핵심 기능 집중, 빠른 개발
- ❌ 포기한 것: 복잡한 인증 시스템 구현 경험

---

## 8. 데이터 규모

### 결정: 설계 100만건, 데모 30만건

**선택 이유**:

1. **설계**: Chunk ETL, 인덱스로 대용량 대응 구조 증명
2. **데모**: Railway Hobby Plan 리소스 제약 고려
3. **측정 가능성**: 30만건도 성능 최적화 효과 측정 가능

**Railway 리소스 제약**:

- 메모리: 512MB ~ 8GB (사용량 기반)
- CPU: Shared
- 스토리지: 제한적

**트레이드오프**:

- ✅ 얻은 것: 안정적 배포, 성능 측정 가능
- ❌ 포기한 것: 실제 대용량(100만건) 배포 경험

---

## 9. 가이드라인 기반 설계

### 결정: 임의 점수 배제, 가이드라인 cut-off만 사용

**선택 이유**:

1. **법적 안정성**: 진단 도구 오해 방지
2. **설명 가능성**: 모든 기준에 출처 명시 가능
3. **신뢰성**: 의료 전문가 검증 가능

**구현**:

- 7개 위험요인 flag (true/false)
- `risk_factor_count` (0~7)
- `risk_group` (ATP III 프레임워크 기반)

**대안**:

- 0~100 점수: 가중치 근거 없음 (뇌피셜 위험)
- ML 모델: 학습 데이터/검증 없음

**트레이드오프**:

- ✅ 얻은 것: 법적 안정성, 설명 가능성
- ❌ 포기한 것: 복잡한 예측 모델 구현

---

## 10. 테스트 범위

### 결정: pytest, 핵심 로직 위주 (커버리지 70% 목표)

**선택 이유**:

1. **효율성**: 1주일 내 100% 커버리지는 비현실적
2. **핵심 증명**: Inference 로직, API 엔드포인트만 증명
3. **실무 적합성**: 핵심 비즈니스 로직 테스트가 우선

**테스트 대상**:

- ✅ Inference Layer (위험요인 계산)
- ✅ API 엔드포인트 (5개)
- ✅ 인증 미들웨어
- ❌ Repository Layer (단순 CRUD)
- ❌ 엣지 케이스 전체

**트레이드오프**:

- ✅ 얻은 것: 핵심 역량 증명, 빠른 개발
- ❌ 포기한 것: 완벽한 테스트 커버리지

---

## 11. 배포 플랫폼

### 결정: Railway (AWS/GCP 대신)

**선택 이유**:

1. **빠른 설정**: MySQL, Redis 클릭 몇 번으로 생성
2. **비용**: Hobby $5/월로 충분
3. **학습 곡선**: 복잡한 인프라 설정 불필요

**대안**:

- AWS EC2/RDS: 설정 복잡, 비용 높음
- Docker Compose (로컬): 배포 경험 증명 불가
- GCP: Railway와 유사하나 익숙하지 않음

**트레이드오프**:

- ✅ 얻은 것: 빠른 배포, 안정성
- ❌ 포기한 것: AWS 인프라 설계 경험

---

## 요약

| 결정       | 선택              | 이유                 | 포기한 것            |
| ---------- | ----------------- | -------------------- | -------------------- |
| 주제       | Inference Serving | 백엔드 아키텍처 증명 | AI 모델 개발         |
| 프레임워크 | Flask             | 빠른 학습, 유연성    | Django 기능들        |
| DB         | MySQL             | 요구사항 충족        | PostgreSQL 고급 기능 |
| 캐시       | Redis (통계만)    | 성능 최적화 증명     | 전체 캐싱            |
| ETL        | 레이어 분리       | 운영 안정성          | 실시간 업로드        |
| 인증       | API Key           | 핵심 집중            | JWT/OAuth            |
| 데이터     | 30만건 데모       | Railway 제약         | 100만건 배포         |
| 판정       | 가이드라인 기반   | 법적 안정성          | 복잡한 모델          |
| 테스트     | 70% 커버리지      | 효율성               | 100% 커버리지        |
| 배포       | Railway           | 빠른 설정            | AWS 경험             |

---

**핵심 메시지**: 모든 선택은 **1주일 + 파이썬 비숙련 + JLK 요구사항**을 고려한 합리적 의사결정입니다.
